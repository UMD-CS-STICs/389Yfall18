{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codelab 2: Kalman Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to implement a Kalman filter to track a car moving in the 1D world.\n",
    "\n",
    "## Where are we?\n",
    "\n",
    "We are in line-world, better known as the 1D world that is 100 units long.\n",
    "\n",
    "We want to implement a Kalman filter to implement a move and sense model to track a moving robot. We will first example the prediction updates, and then the measurement updates.\n",
    "\n",
    "Let us take a look at the prediction update equations for both state and covariance (Σ).\n",
    "\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\vec{\\mu_t} = \\mathbf{A}(\\vec{\\mu_{t-1}}) + \\mathbf{B}(\\vec{control\\_signal})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Sigma_{t} = \\mathbf{A} \\Sigma_{t-1}\\mathbf{A}^T + \\mathbf{R}_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**μ**: This is your state, and will be a 2D vector, containing the position and the velocity. Note that even though we are moving in a 1D world, we can make our state have as many dimensions as we want.\n",
    "\n",
    "**control_signal**: This will be a scalar that represents acceleration, or change in velocity.\n",
    "\n",
    "**state_transition_model** (A): This is how your state updates itself. You can think of it as, \"given my current position and velocity, how would I update myself?\"\n",
    "\n",
    "**control_input_model** (B): This is how your state takes into account an external control, and translates it into a state change. You can think of this as translating the acceleration control signal into an actual velocity change.\n",
    "\n",
    "**Σ**: This is your covariance matrix. Think of this as standard deviation extended into multiple dimensions. You may be thinking, \"Why do we have a matrix if we are moving in a 1D world?\" This is because our _state vector is two dimensional because it contains both position and velocity_.\n",
    "\n",
    "**R**: This is the covariance of our movement function. We will define this later on.\n",
    "\n",
    "The state update function denoted above is a function of state and control_signal. However, we still need to figure out what A and B are.\n",
    "\n",
    "### state_transition_model (A)\n",
    "\n",
    "We know that **A** is applied to our state vector, which is a vector that looks like the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\vec{\\mu_t}=\n",
    "\\begin{pmatrix}\n",
    "position \\\\\n",
    "velocity\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, A is the matrix that finds the next state based on the previous one. From the example in class with the bacteria that doubled itself every timestep, A would be 2. For this case, we need to understand how position updates based on velocity to construct A. We know the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split} \n",
    "\\color{deeppink}{p_t} &= \\color{royalblue}{p_{t-1}} + \\Delta t &\\color{royalblue}{v_{t-1}} \\\\ \n",
    "\\color{deeppink}{v_t} &= &\\color{royalblue}{v_{t-1}} \n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assume that our change in time will be 1. We know our state vector is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\vec{\\mu_t}=\n",
    "\\begin{pmatrix}\n",
    "\\color{royalblue}{p_{t-1}} \\\\\n",
    "\\color{royalblue}{v_{t-1}}\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what matrix, when multiplied by that state vector, will yield the updated position and velocity values as depicted by the equation above? Try filling in your A below, and run the block of code until you see \"All tests passed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: Fill in the values for a, b, c, d\n",
    "A = np.array([[a,b],\n",
    "              [c,d]])\n",
    "\n",
    "def test_A_matrix():\n",
    "    test_1 = np.array([3,1])\n",
    "    test_2 = np.array([2,5])\n",
    "    test_3 = np.array([53,0])\n",
    "    if not np.array_equal(np.dot(A, test_1), np.array([4,1])):\n",
    "        return 'Test 1 not passing.'\n",
    "    if not np.array_equal(np.dot(A, test_2), np.array([7,5])):\n",
    "        return 'Test 2 not passing.'\n",
    "    if not np.array_equal(np.dot(A, test_3), np.array([53,0])):\n",
    "        return 'Test 3 not passing.'\n",
    "    return 'All tests passed!'\n",
    "    \n",
    "print(test_A_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have A, we need to construct B. \n",
    "\n",
    "### control_input (B)\n",
    "\n",
    "B is defined as the control_input model. In our case, the control_input will always be acceleration. You can think of this like pressing a gas pedal down in a car - this changes your acceleration, which in turn affects your state.\n",
    "\n",
    "The product of B and the control_signal should yield a 2x1 vector (as that is the size of our state) that should update the state accordingly. In other words, if you know you are pressing down on the accelerator, the velocity should go up.\n",
    "\n",
    "We know the velocity update equation looks like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\color{deeppink}{v_t} = \\color{royalblue}{v_{t-1}} + \\Delta t \\color{royalblue}{a_{t-1}} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can assume the acceleration will be a 1x1 matrix, and the timestep will be 1. Given that B needs to model the above update equation, what would it look like? Put your guess for B below, and then run the tests to see if you got it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in the values for a and b\n",
    "B = np.array([[a],\n",
    "              [b]])\n",
    "\n",
    "def test_B_matrix():\n",
    "    if not np.array_equal(np.dot(B, np.array([[3]])), np.array([[0],[3]])):\n",
    "        return 'Test 1 not passing.'\n",
    "    if not np.array_equal(np.dot(B, np.array([[-2]])), np.array([[0],[-2]])):\n",
    "        return 'Test 2 not passing.'\n",
    "    if not np.array_equal(np.dot(B, np.array([[0]])), np.array([[0],[0]])):\n",
    "        return 'Test 3 not passing.'\n",
    "    return 'All tests passed!'\n",
    "    \n",
    "print(test_B_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must also update our variances within our _covariance matrix_. The equation for the covariance update is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Sigma_{t} = \\mathbf{A} \\Sigma_{t-1}\\mathbf{A}^T + \\mathbf{R}_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of self-driving cars, engineers will measure the variance in movement and then create the R matrix experimentally. In our case, we obviously do not have the resources to do this. So, we will just define it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = np.array([[0.8,0],\n",
    "              [0,0.8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can implement our prediction update!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To multiply to matrices, use np.dot(m1, m2)\n",
    "# To take the transpose of a matrix, use np.transpose(m)\n",
    "\n",
    "def prediction_update(state, covariance, control_signal):\n",
    "    # TODO\n",
    "    return new_state, new_covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement Update\n",
    "\n",
    "The formulas for the measurement update are the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "K_{t} = \\Sigma_{t} C_t^T (C_t \\Sigma_t C_t^T + Q_t)^{-1} \\\\\n",
    "\\mu_t = \\mu_t + K_t(z_t - C_t\\mu_t) \\\\\n",
    "\\Sigma_t = (I - K_tC_t)\\Sigma_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define all of the new variables.\n",
    "\n",
    "**C**: This is the transformation matrix from the state space of your state vector into the space of measurements. In the case of the bacteria example where we measured concentration of a particular chemical that bacteria produce, this would be some sort of equation to convert number of bacteria into expected concentration.\n",
    "\n",
    "**Q**: This is the uncertainty in your sensor. In the bacteria example, this would be how much variation we expect in our sensing of the chemical concentration.\n",
    "\n",
    "**K**: This is known as the _Kalman Gain_. Intuitively, you can think of this as how much we incorporate this measurement into updating our state.\n",
    "\n",
    "**z**: This is your observed measurement.\n",
    "\n",
    "**I**: This is the identity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **C**, we want a matrix that transforms our state vector (p, v) into what we would expect the measurement to be for this state. Again, we are only tracking position. In other words, we need need to find a C such that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "C_t\\begin{pmatrix}\n",
    "p \\\\\n",
    "v\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "p\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you think you got it, fill in C below and use the tests to see if you got it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the values for a and b\n",
    "C = np.array([[a, b]])\n",
    "\n",
    "def test_C_matrix():\n",
    "    if not np.array_equal(np.array([[0]]),np.dot(C, np.array([[0],[3]]))):\n",
    "        return 'Test 1 not passing.'\n",
    "    if not np.array_equal(np.array([[4000]]),np.dot(C, np.array([[4000],[3312]]))):\n",
    "        return 'Test 2 not passing.'\n",
    "    if not np.array_equal(np.array([[48]]),np.dot(C, np.array([[48],[-43214]]))):\n",
    "        return 'Test 3 not passing.'\n",
    "    return 'All tests passed!'\n",
    "print(test_C_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must define **Q**. This is how noisy our sensor is. Typically, this is figured out through running experiments, but we will just tell you that our readings will be noisy with a standard deviation of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = np.array([2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will give to you a function to get our measurements given a state (μ). All this function will do is take your state, convert it into a measurement with the previously defined **C** matrix, and then corrupt it with some noise to simulate real world sensors. Also, let's define **I** because why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_noisy_measurement(state):\n",
    "    z = np.dot(C, state)\n",
    "    return np.random.normal(z[0], Q, 1)\n",
    "\n",
    "I = np.array([[1,0],[0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to write the measurement update!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To calculate the inverse, use np.linalg.inv(m)\n",
    "\n",
    "def measurement_update(state, covariance, z):\n",
    "    # TODO\n",
    "    return new_state, new_covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial State\n",
    "\n",
    "Let's say our initial belief is that we are at position 50 with a velocity of about 20. Let's model this uncertainty by giving our covariance matrix a position variance of 30 (we are very uncertain) and velocity variance of 3. Run the below code to see our initial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "\n",
    "# initial state\n",
    "state = np.array([[0],[0]])\n",
    "covariance = np.array([[1,0],\n",
    "                       [0,10]])\n",
    "\n",
    "# getting numbers for plot\n",
    "position = state[0][0]\n",
    "variance = covariance[0][0]\n",
    "\n",
    "# plot!\n",
    "x = np.linspace(-10, 10, 100)\n",
    "delta = 0.01\n",
    "x = np.arange(-10, 10, delta)\n",
    "y = np.arange(-10, 10, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = mlab.bivariate_normal(X, Y, covariance[0,0], covariance[1,1], state[0,0], state[1, 0], covariance[1,0])\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.contour(X, Y, Z, figsize=(5,5))\n",
    "plt.xlabel('Position', fontsize=14)\n",
    "plt.ylabel('Velocity', fontsize=14)\n",
    "plt.title('Prior Belief', fontsize=20)\n",
    "print('Mean:')\n",
    "print(state)\n",
    "print('Covariance:')\n",
    "print(covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction #1 (Constant Velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's move! With our initial state, it follows that we'd expect to move 20 spaces forward (because that is our velocity) and end up around 80. However, this should add some uncertainty. We can hold off on adding a control signal for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numbers for plot 1\n",
    "position = state[0][0]\n",
    "variance = covariance[0][0]\n",
    "\n",
    "# set up plot 1\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "x = np.linspace(-10, 10, 100)\n",
    "ax1.plot(x,mlab.normpdf(x, position, math.sqrt(variance)),color=\"green\")\n",
    "\n",
    "state, covariance = prediction_update(state, covariance, np.array([[0]]))\n",
    "\n",
    "# get numbers for plot 2\n",
    "position = state[0][0]\n",
    "variance = covariance[0][0]\n",
    "\n",
    "# set up plot 2\n",
    "ax1.plot(x,mlab.normpdf(x, state[0][0], math.sqrt(variance)),color=\"blue\")\n",
    "ax1.set_title('Prior and Posterior in 1D', fontsize=20)\n",
    "ax1.set_xlabel('Position', fontsize=14)\n",
    "ax1.set_ylabel('Probability Denstity', fontsize=14)\n",
    "ax1.legend(['Prior', 'Posterior'])\n",
    "x = np.arange(-10, 10, delta)\n",
    "y = np.arange(-10, 10, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = mlab.bivariate_normal(X, Y, covariance[0,0], covariance[1,1], state[0,0], state[1, 0], covariance[1,0])\n",
    "ax2.contour(X, Y, Z)\n",
    "ax2.set_title('Posterior After Motion', fontsize=20)\n",
    "ax2.set_xlabel('Position', fontsize=14)\n",
    "ax2.set_ylabel('Velocity', fontsize=14)\n",
    "print('Mean:')\n",
    "print(state)\n",
    "print('Covariance:')\n",
    "print(covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like what we'd expect! Our initial distribution was peaky, and it become flatter because movement introduces more uncertainty. Now, let's measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = state[0][0]\n",
    "variance = covariance[0][0]\n",
    "measurement = get_noisy_measurement(state)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "x = np.arange(-10, 20, delta)\n",
    "y = np.arange(-10, 20, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = mlab.bivariate_normal(X, Y, covariance[0,0], covariance[1,1], state[0,0], state[1, 0], covariance[1,0])\n",
    "ax1.contour(X, Y, Z)\n",
    "ax1.plot(x,mlab.normpdf(x, measurement, math.sqrt(Q[0]))*20-10,color=\"blue\")\n",
    "ax1.set_title('Prior and Measurement', fontsize=20)\n",
    "ax1.set_xlabel('Position', fontsize=14)\n",
    "ax1.set_ylabel('Velocity', fontsize=14)\n",
    "state, covariance = measurement_update(state, covariance, measurement)\n",
    "position = state[0][0]\n",
    "variance = covariance[0][0]\n",
    "x = np.arange(-10, 20, delta)\n",
    "y = np.arange(-10, 20, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = mlab.bivariate_normal(X, Y, covariance[0,0], covariance[1,1], state[0,0], state[1, 0], covariance[1,0])\n",
    "ax2.contour(X, Y, Z)\n",
    "ax2.set_title('Posterior Incorporating Measurement')\n",
    "ax2.set_xlabel('Position', fontsize=14)\n",
    "ax2.set_ylabel('Velocity', fontsize=14)\n",
    "print('Mean:')\n",
    "print(state)\n",
    "print('Covariance:')\n",
    "print(covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also exactly what we'd expect! We go from a flat distribution to a much peakier distribution because that is what sensing does. Let's move again, but this time toss in a control signal to start reversing the direction (negative acceleration).\n",
    "\n",
    "### Prediction #2 (Acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "position = state[0][0]\n",
    "variance = covariance[0][0]\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "x = np.linspace(-10, 10, 100)\n",
    "ax1.plot(x,mlab.normpdf(x, position, math.sqrt(variance)),color=\"green\")\n",
    "state, covariance = prediction_update(state, covariance, np.array([[3]]))\n",
    "position = state[0][0]\n",
    "variance = covariance[0][0]\n",
    "ax1.plot(x,mlab.normpdf(x, state[0][0], math.sqrt(variance)),color=\"blue\")\n",
    "ax1.set_title('Prior and Posterior in 1D', fontsize=20)\n",
    "ax1.set_xlabel('Position', fontsize=14)\n",
    "ax1.set_ylabel('Probability Denstity', fontsize=14)\n",
    "ax1.legend(['Prior', 'Posterior'])\n",
    "x = np.arange(-10, 10, delta)\n",
    "y = np.arange(-10, 10, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = mlab.bivariate_normal(X, Y, covariance[0,0], covariance[1,1], state[0,0], state[1, 0], covariance[1,0])\n",
    "ax2.contour(X, Y, Z)\n",
    "ax2.set_title('Posterior After Motion', fontsize=20)\n",
    "ax2.set_xlabel('Position', fontsize=14)\n",
    "ax2.set_ylabel('Velocity', fontsize=14)\n",
    "print('Mean:')\n",
    "print(state)\n",
    "print('Covariance:')\n",
    "print(covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meaurement #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = state[0][0]\n",
    "variance = covariance[0][0]\n",
    "measurement = get_noisy_measurement(state)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,8))\n",
    "x = np.arange(-10, 20, delta)\n",
    "y = np.arange(-10, 20, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = mlab.bivariate_normal(X, Y, covariance[0,0], covariance[1,1], state[0,0], state[1, 0], covariance[1,0])\n",
    "ax1.contour(X, Y, Z)\n",
    "ax1.plot(x,mlab.normpdf(x, measurement, math.sqrt(Q[0]))*20-10,color=\"blue\")\n",
    "ax1.set_title('Prior and Measurement', fontsize=20)\n",
    "ax1.set_xlabel('Position', fontsize=14)\n",
    "ax1.set_ylabel('Velocity', fontsize=14)\n",
    "state, covariance = measurement_update(state, covariance, measurement)\n",
    "position = state[0][0]\n",
    "variance = covariance[0][0]\n",
    "x = np.arange(-10, 20, delta)\n",
    "y = np.arange(-10, 20, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = mlab.bivariate_normal(X, Y, covariance[0,0], covariance[1,1], state[0,0], state[1, 0], covariance[1,0])\n",
    "ax2.contour(X, Y, Z)\n",
    "ax2.set_title('Posterior Incorporating Measurement')\n",
    "ax2.set_xlabel('Position', fontsize=14)\n",
    "ax2.set_ylabel('Velocity', fontsize=14)\n",
    "plt.title('Simplest default with labels')\n",
    "print('Mean:')\n",
    "print(state)\n",
    "print('Covariance:')\n",
    "print(covariance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
